{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (2.1.0)\n",
      "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in /home/codespace/.local/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: openpyxl in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn numpy matplotlib seaborn openpyxl\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Excel file format cannot be determined, you must specify an engine manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03mplaces_df = pd.read_excel(\"/kaggle/input/travelsenseds/Places Dataset.xlsx\")\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03mpreferences_df = pd.read_excel(\"/kaggle/input/travelsenseds/Visitors Preference Dataset.xlsx\") \"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#Load datasets in a local enviorenment.Please copy dataset file paths and paste here accordingly \u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m places_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlaces Dataset.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m preferences_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisitors Preference Dataset.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Displayed the first few rows of the places and preferences datasets to see if it was imported\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/excel/_base.py:1554\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1551\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m   1552\u001b[0m     )\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n\u001b[1;32m   1559\u001b[0m engine \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_option(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.excel.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.reader\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Excel file format cannot be determined, you must specify an engine manually."
     ]
    }
   ],
   "source": [
    "# Function to safely evaluate strings that are lists (for original data inspection)\n",
    "def safely_evaluate(data):\n",
    "    try:\n",
    "        evaluated_data = literal_eval(data)\n",
    "        if isinstance(evaluated_data, list) and all(isinstance(item, str) for item in evaluated_data):\n",
    "            return ' '.join(evaluated_data)\n",
    "        else:\n",
    "            return ''\n",
    "    except (ValueError, SyntaxError):\n",
    "        return ''\n",
    "\n",
    "# Load the datasets as excel files .This is for use in a kaggle enviorenment.\n",
    "\"\"\"\n",
    "places_df = pd.read_excel(\"/kaggle/input/travelsenseds/Places Dataset.xlsx\")\n",
    "preferences_df = pd.read_excel(\"/kaggle/input/travelsenseds/Visitors Preference Dataset.xlsx\") \"\"\"\n",
    "\n",
    "#Load datasets in a local enviorenment.Please copy dataset file paths and paste here accordingly \n",
    "places_df = pd.read_excel(\"Places Dataset.xlsx\")\n",
    "preferences_df = pd.read_excel(\"Visitors Preference Dataset.xlsx\")\n",
    "\n",
    "# Displayed the first few rows of the places and preferences datasets to see if it was imported\n",
    "print(\"First few rows of Places Dataset:\")\n",
    "print(places_df.head())\n",
    "\n",
    "print(\"First few rows of Preferences Dataset:\")\n",
    "print(preferences_df.head())\n",
    "\n",
    "# Visualization of original data to get an idea about what kind of output we can expect\n",
    "# Visualizing the distribution of ratings in the places dataset\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(places_df['rating'].dropna(), bins=10, kde=True, color='blue')\n",
    "plt.title('Distribution of Ratings in Places Dataset')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Visualizing the count of preferred activities in the preferences dataset\n",
    "plt.figure(figsize=(10, 5))\n",
    "preferences_df['Preferred Activities'].apply(lambda x: safely_evaluate(x)).value_counts().head(10).plot(kind='bar', color='green')\n",
    "plt.title('Top 10 Preferred Activities in Preferences Dataset')\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'places_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Vectorize the original places data\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mplaces_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest_reviews\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: safely_evaluate(x)))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Vectorize user preferences\u001b[39;00m\n\u001b[1;32m     19\u001b[0m user_preferences_vector \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform(preferences_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreferred Activities\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: safely_evaluate(x)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m preferences_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBucket list destinations Sri Lanka\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: safely_evaluate(x)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'places_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to safely evaluate strings that are lists (for original data inspection)\n",
    "def safely_evaluate(data):\n",
    "    try:\n",
    "        evaluated_data = literal_eval(data)\n",
    "        if isinstance(evaluated_data, list) and all(isinstance(item, str) for item in evaluated_data):\n",
    "            return ' '.join(evaluated_data)\n",
    "        else:\n",
    "            return ''\n",
    "    except (ValueError, SyntaxError):\n",
    "        return ''\n",
    "\n",
    "# Application of TF-IDF vector\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# Vectorize the original places data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(places_df['latest_reviews'].apply(lambda x: safely_evaluate(x)))\n",
    "# Vectorize user preferences\n",
    "user_preferences_vector = tfidf_vectorizer.transform(preferences_df['Preferred Activities'].apply(lambda x: safely_evaluate(x)) + ' ' + preferences_df['Bucket list destinations Sri Lanka'].apply(lambda x: safely_evaluate(x)))\n",
    "# Compute similarity scores between user preferences and places\n",
    "similarity_scores = cosine_similarity(user_preferences_vector, tfidf_matrix)\n",
    "# If similarity scores are calculated, add them to the DataFrame (average of all user preferences)\n",
    "if not similarity_scores.size == 0:\n",
    "    places_df['similarity'] = similarity_scores.mean(axis=0)\n",
    "    # Sort the places DataFrame by similarity score to get recommendations\n",
    "    recommended_places = places_df.sort_values(by='similarity', ascending=False)\n",
    "    \n",
    "    # Display the top 10 recommended places\n",
    "    print(recommended_places[['name', 'similarity']].head(10))\n",
    "    \n",
    "    # Visualization of similarity scores\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(places_df['similarity'].dropna(), bins=30, kde=True, color='purple')\n",
    "    plt.title('Distribution of Similarity Scores')\n",
    "    plt.xlabel('Similarity Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualization of top 10 recommended places\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=recommended_places.head(10), x='name', y='similarity', palette='viridis')\n",
    "    plt.title('Top 10 Recommended Places')\n",
    "    plt.xlabel('Place Name')\n",
    "    plt.ylabel('Similarity Score')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No similarity scores were computed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preferences_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Example: Get top recommendations for a user and plot them\u001b[39;00m\n\u001b[1;32m     43\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m80\u001b[39m  \u001b[38;5;66;03m# Example user ID, adjust based on your data <-----------------------CHANGE THE ID HERE TO TEST THE MODEL and SEE. MAX is 1000\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m user_name, recommendations_sorted \u001b[38;5;241m=\u001b[39m \u001b[43mget_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop Recommendations for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Display the recommendations in a table\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mget_recommendations\u001b[0;34m(user_id, top_n)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recommendations\u001b[39m(user_id, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\u001b[38;5;66;03m#<--------------------------------------------- Specify how many recommendations are needed by top_n\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Check if the user exists in the dataset(max id is 1000)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpreferences_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Get the index of the user\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preferences_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to get recommendations for a user by user ID to get\n",
    "def get_recommendations(user_id, top_n=10):#<--------------------------------------------- Specify how many recommendations are needed by top_n\n",
    "    # Check if the user exists in the dataset(max id is 1000)\n",
    "    if user_id not in preferences_df['User ID'].values:\n",
    "        return f\"User ID {user_id} not found.\"\n",
    "    \n",
    "    # Get the index of the user\n",
    "    user_index = preferences_df[preferences_df['User ID'] == user_id].index[0]\n",
    "    \n",
    "    # Get the user's name\n",
    "    user_name = preferences_df.loc[preferences_df['User ID'] == user_id, 'Name'].values[0]\n",
    "\n",
    "    # Get the similarity scores for that user\n",
    "    user_scores = similarity_scores[user_index]\n",
    "    \n",
    "    # Sort places by similarity score for this user\n",
    "    recommended_indices = user_scores.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    # Get the top n recommended places\n",
    "    recommended_places = places_df.iloc[recommended_indices].copy()\n",
    "    \n",
    "    # Add a column for the user's name in the recommendations\n",
    "    recommended_places['User Name'] = user_name\n",
    "    \n",
    "    # Reset index for readability (1-based index)\n",
    "    recommended_places.index = recommended_places.index + 1\n",
    "    \n",
    "    # Sort recommendations by rating in descending order\n",
    "    recommendations_sorted = recommended_places.sort_values(by='rating', ascending=False)\n",
    "    \n",
    "    return user_name, recommendations_sorted[['name', 'formatted_address', 'rating', 'latest_reviews']]\n",
    "\n",
    "# Function to plot the recommendations as a bar chart\n",
    "def plot_recommendations(recommendations_sorted, user_name):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    sns.barplot(x='rating', y='name', data=recommendations_sorted, palette='viridis')\n",
    "    plt.title(f\"Top Recommendations for {user_name} Based on Ratings\")\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Place')\n",
    "    plt.show()\n",
    "\n",
    "# Example: Get top recommendations for a user and plot them\n",
    "user_id = 80  # Example user ID, adjust based on your data <-----------------------CHANGE THE ID HERE TO TEST THE MODEL and SEE. MAX is 1000\n",
    "user_name, recommendations_sorted = get_recommendations(user_id)\n",
    "\n",
    "print(f\"Top Recommendations for {user_name}\")\n",
    "\n",
    "# Display the recommendations in a table\n",
    "display(recommendations_sorted)\n",
    "\n",
    "# Plot the recommendations for the user\n",
    "plot_recommendations(recommendations_sorted.head(10), user_name)  #<---------------change the number within head(#) to change the number of datapoints in graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarity_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#SAVING the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Created a dictionary to store all components together to avoide it being messy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_components \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf_vectorizer\u001b[39m\u001b[38;5;124m'\u001b[39m: tfidf_vectorizer,\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity_scores\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43msimilarity_scores\u001b[49m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplaces_df\u001b[39m\u001b[38;5;124m'\u001b[39m: places_df,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreferences_df\u001b[39m\u001b[38;5;124m'\u001b[39m: preferences_df\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# And saved all components into a single .pkl file\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'similarity_scores' is not defined"
     ]
    }
   ],
   "source": [
    "#SAVING the model\n",
    "\n",
    "# Created a dictionary to store all components together to avoide it being messy\n",
    "model_components = {\n",
    "    'tfidf_vectorizer': tfidf_vectorizer,\n",
    "    'similarity_scores': similarity_scores,\n",
    "    'places_df': places_df,\n",
    "    'preferences_df': preferences_df\n",
    "}\n",
    "\n",
    "# And saved all components into a single .pkl file\n",
    "with open('combined_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_components, f)\n",
    "\n",
    "print(\"Model components saved successfully in 'combined_model.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING the model\n",
    "\n",
    "\n",
    "with open('combined_model.pkl', 'rb') as f:\n",
    "    model_components = pickle.load(f)\n",
    "\n",
    "#Or can access individual components \n",
    "tfidf_vectorizer = model_components['tfidf_vectorizer']\n",
    "similarity_scores = model_components['similarity_scores']\n",
    "places_df = model_components['places_df']\n",
    "preferences_df = model_components['preferences_df']\n",
    "\n",
    "print(\"Model components loaded successfully from 'combined_model.pkl'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
